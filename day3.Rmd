---
title: "Lab 3  -- Classification"
author: "Philipp Broniecki and Lucas Leemann -- Machine Learning 1K"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### (based on James et al. 2013)

### The Non-Western Foreigners Data Set

We start by clearing our workspace.

```{r}
# clear workspace
rm(list = ls())
```


Let's check the codebook of our data.

|Variable Name|Description|
|--------|-----------------------------------------------------------|
|IMMBRIT | Out of every 100 people in Britain, how many do you think are immigrants from Non-western countries?|
|over.estimate | 1 if estimate is higher than 10.7%. |
|RSex | 1 = male, 2 = female |
|RAge | Age of respondent |
|Househld | Number of people living in respondent's household |
|Cons, Lab, SNP, Ukip, BNP, GP, party.other | Party self-identification|
|paper | Do you normally read any daily morning newspaper 3+ times/week? |
|WWWhourspW | How many hours WWW per week? |
|religious | Do you regard yourself as belonging to any particular religion? |
|employMonths | How many mnths w. present employer? |
|urban | Population density, 4 categories (highest density is 4, lowest is 1) |
|health.good | How is your health in general for someone of your age? (0: bad, 1: fair, 2: fairly good, 3: good) |
|HHInc | Income bands for household, high number = high HH income |

```{r}
# load non-western foreigners data set
load("./data/BSAS_manip.RData")
df <- data2 # make a copy with a shorter name
rm(data2) # remove the original with longer name

names(df)
dim(df)
summary(df)

# data manipulation
df$RSex <- factor(df$RSex, labels = c("Male", "Female"))
df$health.good <- factor(df$health.good, labels = c("bad", "fair", "fairly good", "good") )

# urban to dummies (for knn later)
table(df$urban) # 3 is the modal category (keep as baseline) but we create all categories
df$rural <- ifelse( df$urban == 1, yes = 1, no = 0)
df$partly.rural <- ifelse( df$urban == 2, yes = 1, no = 0)
df$partly.urban <- ifelse( df$urban == 3, yes = 1, no = 0)
df$urban <- ifelse( df$urban == 4, yes = 1, no = 0)

# pairwise comparisons (for a managable subset of the data)
pairs(df[, c("IMMBRIT", "RAge", "Househld", "employMonths", "WWWhourspW", "HHInc")])

# correlations
cor(df[,c("IMMBRIT", "RAge", "Househld", "employMonths", "WWWhourspW",  "HHInc")])


# how good are we at guessing immigration
boxplot(df$IMMBRIT, 
        main = "Perception of Immigration from Non-Western Countries",
        ylab = "Subjective number of immigrants per 100 British", 
        frame.plot = FALSE, col = "darkgray")

# by party affiliation
par( mfrow = c(1, 6) ) # plot window separated into 1 row and 6 columns
boxplot(df$IMMBRIT[ df$Cons == 1],  frame.plot = FALSE, main = "Tories", col = "#114477", ylim = c(0, 100))
boxplot(df$IMMBRIT[ df$Lab == 1], frame.plot = FALSE, main = "Labour", col = "#AA4455", ylim = c(0, 100))
boxplot(df$IMMBRIT[ df$SNP == 1], frame.plot = FALSE, main = "SNP", col = "#DDDD77", ylim = c(0, 100))
boxplot(df$IMMBRIT[ df$GP == 1], frame.plot = FALSE, main = "Greens", col = "#44AA77", ylim = c(0, 100))
boxplot(df$IMMBRIT[ df$Ukip == 1], frame.plot = FALSE, main = "Ukip", col = "#AA4488", ylim = c(0, 100))
boxplot(df$IMMBRIT[ df$BNP == 1], frame.plot = FALSE, main = "BNP", col = "#AA7744", ylim = c(0, 100))
```

### Logistic Regression

We want to predict whether respondents over-estimate immigration from non-western contexts. We begin by normalizing our variables. Then we look at the distribution of the dependent variable. We check how well we could predict misperception of immigration in our sample without a statistical model.

```{r}
# create a copy of the original IMMBRIT variable (needed for classification with lm)
df$IMMBRIT_original_scale <- df$IMMBRIT

# our function for normalization
our.norm <- function(x){
  return((x - mean(x)) / sd(x))
}

# continuous variables
c.vars <- c("IMMBRIT", "RAge", "Househld", "HHInc", "employMonths", "WWWhourspW")

# normalize
df[, c.vars] <- apply( df[, c.vars], 2, our.norm )

# predict whether poeple overestimate rate of immigrants (i.e. more than 10.7%)
table(df$over.estimate)

# probability of misperception of immigration in the sample
mean(df$over.estimate)  

# naive guess
median(df$over.estimate)
```

Now, we fit a logistic regression.

```{r}
# run logistic regression
m.log <- glm(over.estimate ~ RSex + RAge + Househld + Lab + SNP + Ukip + BNP + 
               GP + party.other + paper + WWWhourspW +  religious + 
               employMonths + rural + partly.rural + urban + 
               health.good + HHInc, data = df,
             family = binomial(link = "logit"))
summary(m.log)
```


There are also two other ways to look at the estimated parameters of our model. We can just call the coefficients or we can exploit that they are an object within the summary object of the model object.

```{r}
# extract coeffiecients only
coef(m.log)

# only estimates table of summary
summary(m.log)$coef

# display p-values only
summary(m.log)$coef[, 4]
```

The parameters may be of interest if inference is our goal. But if we are just interested in classification we would like to make predictions. This can be done directly by using the predict() function:

```{r}
# predict probabilities
pred.probs <- predict( m.log, type = "response")
pred.probs[1:10] # predictions for the first 10 respondents
```

To see how good our classification model is we need to compare the classification with the actual outcomes. We first create an object `exp.out` which will be either `0` or `1`. In a second step, we cross-tab it with the true outcomes and this allows us to see how well the classification model is doing.

```{r}
# predict whether respondent over-estimates or not
exp.out <- ifelse( pred.probs > 0.5, yes = 1, no = 0)

# confusion matrix (table of predictions and true outcomes)
table(prediction = exp.out, truth = df$over.estimate)
```

The diagonal elements are the correct classifications and the off-diagonal ones are wrong. We can compute the share of correct classified observations as a ratio.

```{r}
# percent correctly classified
(41 + 719) / 1049
```

We can also write code that will estimate the percentage correctly classified for different values.

```{r}
# more generally
mean( exp.out == df$over.estimate)
```

This is the performance on the training data and we expect the test error to be higher than this. To get at a better indication of the model's classification error we can split the dataset into a training set and a test set.

```{r}
# set the random number generator
set.seed(12)

# random draw of 80% of the observation (row numbers) to train the model
train.ids <- sample(nrow(df), size = as.integer( (nrow(df)*.80) ), replace = FALSE)

# the validation data 
df.test <- df[ -train.ids, ]
dim(df.test)
```

Now we fit the model using the training data only and then test its performance on the test data.

```{r}
# re-fit the model on the raining data
m.log <- glm(over.estimate ~ RSex + RAge + Househld + Lab + SNP + Ukip + BNP + 
               GP + party.other + paper + WWWhourspW +  religious + 
               employMonths + rural + partly.rural + urban + health.good + 
               HHInc, data = df, subset = train.ids, 
             family = binomial(link = "logit"))

# predict probabilities of over-estimating but for the unseen data
pred.probs <- predict(m.log, newdata = df.test, type = "response")

# classify predictions as over-estimating or not
exp.out <- ifelse( pred.probs > 0.5, yes = 1, no = 0)

# confusion matrix of predictions against truth
table( prediction = exp.out, truth = df.test$over.estimate)

# percent correctly classified
mean( exp.out == df.test$over.estimate )
```

We see that the classification accuracy is too high in the training dataset. The accuracy on the test dataset provides a good estimate of the model's abbility to correctly identify observations.

Let's try to improve the classification model by relying on the best predictors.

```{r}
# try to improve the prediction model by relying on "good" predictors
m.log <- glm(over.estimate ~ RSex + rural + partly.rural + urban + HHInc, 
             data = df, subset = train.ids, family = binomial(link = "logit"))
pred.probs <- predict(m.log, newdata = df.test, type = "response")
exp.out <- ifelse( pred.probs > 0.5, yes = 1, no = 0)
table( prediction = exp.out, truth = df.test$over.estimate )
mean( exp.out == df.test$over.estimate )
```

We see that the classification model's accurcy increases when we only rely the strongest predictors.

You can also make predictions for specific settings:

```{r}
# prediction for a specific setting
predict(m.log, newdata = data.frame( RSex = c("Male", "Female"),
                                     rural = c(0, 0),
                                     partly.rural = c(0, 0),
                                     urban = c(0, 0),
                                     HHInc = c(9, 9)), type = "response")
```


### Linear Discriminant Analysis
```{r}
library(MASS)
```

```{r}
# fit model
m.lda <- lda( over.estimate ~ RSex + rural + partly.rural + urban + HHInc, 
              data = df, subset = train.ids)
m.lda

# predict outcomes on test set
lda.pred <- predict(m.lda, newdata = df.test)

# check prediction object
names(lda.pred)

# predicted probabilities
pred.probs <- lda.pred$posterior[, 2]

# predict returns predicted classification directly
exp.out <- lda.pred$class

# confusion matrix
table( prediction = exp.out, truth = df.test$over.estimate)

# percent correctly classified
mean( exp.out == df.test$over.estimate )
```

As is often the case, we get similar model performace from the logistic regression as from LDA.

You can also generate these predictions yourself and this will allow you to vary the threshold:

```{r}
# generate classification ourselves with different thresholds
sum( pred.probs >= .40 ) # over-estimates
sum( pred.probs < .40) # realistic evaluation
```

### K-Nearest Neighbors

For KNN we need to provide the data in a slightly different format:

```{r}
library(class)

# training & test data set of predictor variables only
train.X <- cbind( df$RSex, df$rural, df$partly.rural, df$urban, df$HHInc )[train.ids, ]
test.X <- cbind( df$RSex, df$rural, df$partly.rural, df$urban, df$HHInc )[-train.ids, ]

# response variable for training observations
train.Y <- df$over.estimate[ train.ids ]

# re-setting the random number generator
set.seed(123)

# run knn
knn.out <- knn(train.X, test.X, train.Y, k = 1)

# confusion matrix
table( prediction = knn.out, truth = df.test$over.estimate )

# percent correctly classified
mean( knn.out == df.test$over.estimate )
```

We can try and increase the accuracy by changing the number of nearest neighbors we are using:

```{r}
# try to increae accuracy by varying k
knn.out <- knn(train.X, test.X, train.Y, k = 7)
mean( knn.out == df.test$over.estimate )
```

### Model the Underlying Continuous Process

Lastly, we can try to model the underlying process and classify afterwards. By doing that, the depdendent variable provides more information. In effect we turn our classification problem into a regression problem.

```{r}
# fit the linear model on the numer of immigrants per 100 Brits
m.lm <- lm(IMMBRIT ~ RSex + rural + partly.rural + urban + HHInc, 
            data = df, subset = train.ids)

# predictions by "hand"
betas <- as.matrix(coef(m.lm))
X <- cbind( 1, df.test$RSex == "Female", 
            df.test$rural,
            df.test$partly.rural,
            df.test$urban,
            df.test$HHInc)

# yhat (y_hat = X * betas)
y_hat <- X %*% betas

# alternatively using predict
y_hat2 <- predict(m.lm, newdata = df.test)

# check that both are similar
all(y_hat == y_hat2)

# threshold for classfication
threshold <- (10.7 - mean(df$IMMBRIT_original_scale)) / sd(df$IMMBRIT_original_scale)

# now we do the classfication 
exp.out <- ifelse( y_hat > threshold, yes = 1, no = 0)

# confusion matrix
table( prediction = exp.out, truth = df.test$over.estimate)

# percent correctly classified
mean( exp.out == df.test$over.estimate)
```

We do worse by treating this as a regression problem rather than a classification problem.

### Exercises

### Q1

In this problem, you will develop a model to predict whether a given car gets high or low gas mileage based on the Auto dataset from the ISLR package. Start by loading `library(ISLR)`. Check the codebook of the Auto data set that comes with the ISLR package by typing `?Auto`.

  + Create a binary variable, `mpg01`, that contains a 1 if `mpg` contains a value above its median, and a 0 if `mpg`
  contains a value below its median. You can compute the median using the `median()` function. Note you may find it
  helpful to use the `data.frame()` function to create a single data set containing both `mpg01` and the other Auto
  variables.
  + Explore the data graphically in order to investigate the association between mpg01 and the other features. Which
  of the other features seem most likely to be useful in predicting `mpg01`? Scatterplots and boxplots may be useful
  tools to answer this question. Describe your findings.
  + Split the data into a training set and a test set.
  + Perform LDA on the training data in order to predict `mpg01` using the variables that seemed most associated with
  `mpg01` in (b). What is the test error of the model obtained?
  Perform logistic regression on the training data in order to predict `mpg01` using the variables that seemed most
  associated with `mpg01` in (b). What is the test error of the model obtained?
  + Perform KNN on the training data, with several values of K, in order to predict `mpg01`. Use only the variables
  that seemed most associated with `mpg01` in (b). What test errors do you obtain? Which value of K seems to perform
  the best on this data set?
  + Write a loop and try to find systematically the best value for K.

### Q2

This problem involves writing functions.

  + Write a function, `Power()`, that prints out the result of raising 2 to the 3rd power. In other words, your
  function should compute $2^3$ and print out the results.
  
    Hint: Recall that $x^a$ raises x to the power a. Use the `print()` function to output the result.
  
  + Create a new function, `Power2()`, that allows you to pass any two numbers, x and a, and prints out the value of
  $x^a$. You can do this by beginning your function with the line
  
```{r, eval=FALSE}
Power2 <- function(x, a){
```

You should be able to call your function by entering, for instance,

```{r, eval=FALSE}
Power2(2, 8)
```

on the command line. This should output the value of $3^8$, namely, 6,561.

  + Using the `Power2()` function that you just wrote, compute $10^3$, $8^17$, and $131^3$.
  
  + Now create a new function, `Power3()`, that actually returns the result $x^a$ as an R object, rather than simply
  printing it to the screen. That is, if you store the value $x^a$ in an object called result within your function,
  then you can simply return() this result, using the following line:
  
```{r, eval=FALSE}
return(result)
```

The line above should be the last line in your function, before the `}` symbol that closes the function.

  + Now using the `Power3()` function, create a plot of $f(x) = x^2$. The $x$-axis should display a range of integers
  from 1 to 10, and the $y$-axis should display $x^2$. Label the axes appropriately, and use an appropriate title for
  the figure. Consider displaying either the $x$-axis, the $y$-axis, or both on the log-scale. You can do this by
  using `log = "x"`, `log = "y"`, or `log = "xy"` as arguments to the `plot()` function.
  
  + Create a function, `PlotPower()`, that allows you to create a plot of $x$ against $x^a$ for a fixed $a$ and for a
  range of values of $x$. For instance, if you call

```{r, eval=FALSE}
PlotPower3( 1:10, 3 )
```

  then a plot should be created with an $x$-axis taking on values $1,2,\ldots,10$ and a $y$-axis taking on values
  $1^3,2^3,\ldots,10^3$.
